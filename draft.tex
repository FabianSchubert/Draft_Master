\documentclass[10pt,a4paper]{article}
%\usepackage{layouts}
\usepackage[a4paper,margin=1.5in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{caption}
\captionsetup[table]{singlelinecheck=false}
\captionsetup[figure]{singlelinecheck=false}

\usepackage{setspace}
\makeatletter
\newcommand{\MSonehalfspacing}{%
  \setstretch{1.44}%  default
  \ifcase \@ptsize \relax % 10pt
    \setstretch {1.448}%
  \or % 11pt
    \setstretch {1.399}%
  \or % 12pt
    \setstretch {1.433}%
  \fi
}

%\makeatother
%\MSonehalfspacing

\title{Diffusive Homeostasis in a Self-Organizing Recurrent Neural Network \\
\begin{large}
Spatially dependent Interaction as a Determinant of Neural Activity and Plasticity
\end{large}
}


\begin{document}
\maketitle
\section{Abstract} \label{abstract}
We attempted to replace the intrinsic homeostatic control system used in the original version by a mechanism based on the diffusion of a neurotransmitter across the nervous tissue based on the LIF-SORN-model proposed in \cite{SORN_Paper}. The model of diffusive homeostasis was adopted from a paper by Y. Sweeney et al. \cite{Sweeney_Paper} and models the tissue as a surface of square shape and a set of points on this surface, representing the neurons' positions within the SORN. The group of excitatory neurons then acted as a point-source of nitric oxide (NO), as well as as a sensor for the NO-concentration at each individual position. The production and sensing of NO forms the basis of a feedback loop: The individual NO-readout is fed into a comparator which causes an appropriate change within the internal firing threshold of the neuron, in turn altering the neuron's firing rate. The control system is then closed by linking the rate of NO-production to the neuron's firing rate.

Key aspects of this thesis include an analysis of the stability of the homeostatic control, followed by a comparison of features of the original LIF-SORN and the Diffusive variant. We expect to observe a preservation of non-random features that have been found in the original LIF-SORN while incorporating a stronger variance within neural activity (as reported by \cite{Sweeney_Paper}) which has previously been suppressed by a rigid single-cell homeostasis. In the face of possible \emph{new} features within the network's structure, one should further clarify the - presumably indirect - causal relation between diffusive spatial interaction and synaptic topology. 





\section{Methods} \label{methods}
\subsection{Network Simulation} \label{network simulation}

The Neural Network was simulated with the code used in \cite{SORN_Paper}, which makes use of the BRIAN spiking neural network simulator \cite{Briansim}. Thus, all following explanations regarding the simulation of neurons and mechanisms of synaptic plasticity are based on the methods described in the aforementioned paper.

Across a square area of 1000 $\times$ 1000 $\mu m$, 400 excitatory LIF neurons and 80 inhibitory LIF neurons where assigned random positions. Before the start of the simulation, all but recurrent excitatory synapses where randomly generated until a desired connection fraction was reached. The connection probability between two neurons was calculated from a distant dependent Gaussian function with a standard deviation of 200 $\mu m$. For exc. to inh. (EI) and inh. to exc. (IE) synapses, the connection fraction was set to 0.1, and 0.5 for recurrent inh. synapses (II). These connections where kept at a fixed connection strength throughout the simulation. Furthermore, all synapses where simulated with a fixed (distance independent) conduction delay. See table \ref{syn_conn_params} for a summary of parameters.

Recurrent excitatory synapses where subject to a number of plastic mechanisms to be described in the following. 

\begin{table}
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{parameter} & \textbf{EE} & \textbf{EI} & \textbf{IE} & \textbf{II} \\ \hline
connection fraction & $\rightarrow 0.1$ & $0.1$ & $0.1$ & $0.5$ \\ \hline
initial connection strength & $0.0001 mV$ & $1.5 mV$ & $-1.5 mV$ & $-1.5 mV$ \\ \hline
conduction delay & $1.5 ms$ & $0.5 ms$ & $1.0 ms$ & $1.0 ms$ \\
\hline
\end{tabular}
\caption{Parameters of synaptic connections.}
\label{syn_conn_params}
\end{table}

\subsubsection{Synaptic Plasticity}

\textbf{Synaptic Growth:} At a rate of 1/sec, the random, distance dependent generation of new EE synapses was carried out n times, where n is taken from a normal distribution with mean 920 and standard deviation $\sqrt{920}$. This constant growth rate was tuned to achieve the desired target concentration of 0.1 (see \ref{syn_conn_params}).

\textbf{Synaptic Pruning:} At the same rate of 1/sec, EE synapses below a threshold of 0.000001 mV where removed, thus being added again to the set of "potential" connections from which the growth process draws new connections. Especially, they were temporarily excluded from STDP (see below).

\textbf{Spike Timing Dependent Plasticity:} An additive STDP rule was used as described e.g. in \cite{Zhang_STDP}. The change of weight between two neurons due to a pre- and postsynaptic spike (i $\rightarrow$ j) is defined as:
\begin{align}
\Delta w_{ji} &= \sum_k \sum_l W(t_j^l - t_i^k) \label{STDP_rule} \\
W(\Delta t) &= A_{+} exp(-\Delta t / \tau_{+}), & \Delta t > 0 \label{STDP_pos} \\
W(\Delta t) &= A_{-} exp(\Delta t / \tau_{-}), & \Delta t < 0 \label{STDP_neg}
\end{align}
Indexes k and l refer to the kth and lth pre- and postsynaptic spike respectively. Parameters where chosen to approximate data from \cite{Bi_Poo_STDP} and \cite{Froemke_STDP}, namely $\tau_{+} = 15 ms$, $A_{+} = 15 mV$, $\tau_{-} = 30 ms$ and $A_{-} = -7.5 mV$. However, for the sake of reduction of computational effort, we used the "nearest neighbor" approximation, only calculating the effect of the most recent pre-post pair of spikes for potentiation and post-pre pair for depression, yielding roughly the same value as the full summation due to the fast decay times $\tau_{+}$ and $\tau_{-}$ of the STDP-window.

\textbf{Synaptic Normalization:} Among other, experiments have suggested rescaling of synapses among individual postsynaptic neurons as a form of activity regulation in the brain: While preserving ratios of weights, the mean incoming connectivity is multiplicatively adjusted. While this general mechanism has been confirmed in many experiments, results differ regarding the question whether the target connectivity is dynamically changing in order to preserve a certain postsynaptic firing rate (homeostatic synaptic scaling), or whether it remains constant, effectively enforcing a synaptic normalization. Though the latter does not directly enforce a fixed level of activity, one can argue that in a balanced recurrent network, synaptic normalization still reduces the probability of very high or low firing rates caused by an above- or below-average total synaptic input.

We implemented synaptic normalization by calling a function once per sec., updating each $w_{ji}$ from neuron $i$ to neuron $j$ as follows:

\begin{equation}
w_{ji} \rightarrow w_{ji} \frac{w_{total}}{\sum_i w_{ji}}
\label{Synnnorm}
\end{equation}

$w_{total}$ was set to different values for each of the four types of connections between the excitatory and inhibitory pool of neurons. Except for the dynamically populated EE-synapses, these values could be directly set in accordance with the previously given parameters of desired mean individual connection strength, size of the presynaptic population and connection fraction, by calculating $w_{total} = w_{mean} \cdot N_{presyn. pop}\cdot p_{connect}$. This yielded $w_{total,EI} = 60 mV$, $w_{total,IE} = -12 mV$, $w_{total,II} = -60 mV$. $w_{total,EE}$ was set to $40mV$,  corresponding to a mean synaptic weight of $1mV$, given a targeted EE-connection fraction of $0.1$ and a population of 400 excitatory neurons.

\textbf{Short Term Plasticity:} As an additional stabilization of network activity, a short term plasticity (STP) mechanism acting on recurrent excitatory connections was implemented as presented in \cite{Markram_STP}. It modulates the effective synaptic weights by multiplying the value stored in the weight matrix $w_{ji}$ by two dynamic variables $x$ and $u$, $w^{effective}_{ji} = w_{ji}\cdot x \cdot u$, each synapse owning a pair $(x,u)$. The dynamics of these variables are given by:

\begin{equation}
\dot{x} = \frac{1-x}{\tau_d},\; \dot{u} = \frac{U-u}{\tau_f}
\label{STP_dynamics1}
\end{equation}
Furthermore, each presynaptic spike causes a change of $x$ and $u$ by
\begin{equation}
x \rightarrow x - x\cdot u,\; u \rightarrow u + U(1-u)
\label{STP_dynamics2}
\end{equation}

If no spikes arrive, the system rests at $x\cdot u = U$. Otherwise, depending on the choice of $\tau_d$ and $\tau_f$, one can achieve a weight modulation that is dominated by potentiation ($\tau_f \gg \tau_d$) or depression ($\tau_f \ll \tau_d$). As a rough approximation of the values that where experimentally observed \cite{Markram_STP}, we chose $U=0.04$, $\tau_d = 0.5s$ and $\tau_f = 2s$, giving it a tendency towards potentiation. However, one should keep in mind that for $U\in [0,1]$, $x\cdot u \in [0,1]$ always holds, thus the factor $x\cdot u$ has a generally diminishing effect. E.g., for our choice of variables, a poisson input with a constant rate achieves the best synaptic transmission at a rate of $\sim 4.5 Hz$, corresponding to $x\cdot u \approx 0.2$. "Potentiation" in this context refers to the fact that stronger input strengthens synaptic transmission \emph{compared} to close to zero incoming spikes.

\subsubsection{Neuron Model}

We used a leaky integrate-and-fire-model for all neurons in the network, whose dynamics are described by a stochastic differential equation:
\begin{equation}
{\tau_m}dV = -(V-E_l)dt + \sqrt{\tau_m} \sigma dW
\label{LIF_Dynamics}
\end{equation}
where $V$ is the membrane potential, $E_l$ is the equilibrium membrane potential, $\tau_m$ is the time constant of the membrane, $\sigma$ is the standard deviation of the noise term and $dW$ is the standard Wiener process. A neuron is said to spike when its membrane potential reaches the threshold voltage $V_t$. The voltage is then reset to $V_r$. A refractory period was not implemented. A presynaptic spike causes a simple (delayed, see Table \ref{syn_conn_params}) increment of the membrane potential of the postsynaptic neuron by $w^{effective}_{ji}$. Table \ref{LIF_neuron_params} summarizes the aforementioned set of parameters.
\begin{table}
\begin{tabular}{|l|l|l|}
\hline
\textbf{parameter} & \textbf{exc. neur.} & \textbf{inh. neur.}\\ \hline
$\mathrm{E_l}$ & $\mathrm{-60\;mV}$ & $\mathrm{-60\;mV}$ \\ \hline
$\mathrm{\tau_m}$ & $\mathrm{20\;ms}$ & $\mathrm{20\;ms}$ \\ \hline
$\mathrm{V_r}$ & $\mathrm{-70\;mV}$ & $\mathrm{-60\;mV}$ \\ \hline
$\mathrm{\sigma}$ & $\mathrm{\sqrt{5}\;mV}$ & $\mathrm{\sqrt{5}\;mV}$ \\ \hline
$\mathrm{V_t}$ & subject to IP & $\mathrm{-58\;mV}$ \\ 
\hline
\end{tabular}
\caption{Parameters of LIF neuron}
\label{LIF_neuron_params}
\end{table}   

\subsubsection{Intrinsic Plasticity (IP)}

Apart from dynamic processes within synapses which contribute to a stabilization of the network's activity, neurons possess internal mechanisms capable of maintaining a desired regime of activity. Regular-spiking cells are known to down-(up-)regulate their firing rate upon increased (decreased) input on a timescale of tens of milliseconds \cite{Connors_Gutnick_Spike_Patterns,Benda_Herz_Spike_Frequ_Adaption}. Since our simulation did not incorporate any rapidly changing external drive, the network itself was not expected to exhibit fast changes of synaptic input, allowing us to neglect this feature. On the other hand, a similar form of adaption as a reaction on deprived or enhanced input can be observed on a timescale of hours to days \cite{Desai_IP}. In contrast to the former short-term adaption, which can be explained by a separation of timescales among different ionic currents in the cell \cite[p.~252-256]{Izhikevich_Dynsys}, in the latter case, \cite{Desai_IP} finds evidence that a long-term change in excitability can be attributed to an altered resistance of ionic channels.

In the original LIF-SORN, a simple form of low intrinsic homeostasis was implemented by altering the neurons' firing threshold based on the deviation from a target firing rate. This thesis implemented a new model of slow intrinsic homeostasis, based on the work in \cite{Sweeney_Paper}. The following section describes both models in further detail.


\subsubsection{Modelling of Homeostatic Intrinsic Plasticity}

Our original model of homeostatic control was described as an operation over discrete time steps $\Delta t = 0.1ms$, carried out for each excitatory neuron:

\begin{align}
V_t &\rightarrow V_t + \eta_{IP} (N_{spikes} - h_{IP}) \label{can_hom_1}\\
N_{spikes} &\rightarrow 0 \label{can_hom_2}
\end{align}
where $V_t$ is the firing threshold, $\eta_{IP}$ an adaption rate and $h_{IP}$ the desired number of spikes per time step. $N_{spikes}$ is a variable, counting the number of spikes of the neuron within each interval. In a continuous, rate-based form, this update rule can as well be written as:

\begin{equation}
\dot{V}_t = \eta_{IP}(r-r_{IP}) \label{can_hom_rate}
\end{equation}
with $r$ as the neuron's firing rate and $r_{IP}=h_{IP}/\Delta t$ the target firing rate. This feedback control indirectly drives the firing rate of each neuron towards $r_{IP}$: If $r>(<)r_{IP}$, $V_t$ increases (decreases), reducing (increasing) the probability of a spike to occur. 

The model presented in \cite{Sweeney_Paper} includes spatial interaction across excitatory neurons through the diffusion of nitric oxide (NO). Enzymes that are responsible for NO synthase (NOS) are present in different areas of the body, namely being involved in the dilation of blood vessels (endothelial NOS, eNOS) , the immune system (inducible NOS, iNOS) and the CNS (neuronal NOS, nNOS) \cite{NOS_Mammals}. These Enzymes differ in their functionality and dependence on the presence of other molecules. In particular, nNOS is sensitive to the concentration of $Ca^{2+}$ ionic Calcium \cite{Knowles_Ca_nNOS}.

Due to a depolarization of the membrane potential in the course of an action potential, voltage dependent $Ca^{2+}$-channels open, which causes a significant increase of the intracellular Calcium concentration (relative to the low concentration at rest) \cite[p.~98-100]{Hille_Ion_Channels}. A common theoretical description of voltage-dependent ion channels is provided by the Goldman-Hodgkin-Katz equations, see \cite[p.~445-451]{Hille_Ion_Channels}. As such, $Ca^{2+}$ constitutes a causal link between spiking activity and the production of NO.

On the other hand, experimental studies have suggested that NO can act as a diffusive signalling pathway, decreasing intrinsic excitability \cite{Steinert_NO}, or generally suggest a role of NO in maintaining a functional state of activity \cite{Pape_NO}.

Sweeney et al. combined these empirical findings into a model of \emph{diffusive homeostasis}, which is governed by the following equations:   

\begin{align}
\dot{{Ca^{2+}}^i}(t) &= -\frac{{Ca^{2+}}^i}{\tau_{Ca^{2+}}} + Ca^{2+}_{spike} \sum_{j} \delta(t-t^i_{spike,j}) \label{Ca_dyn}\\
\dot{nNOS^i}(t) &= \frac{1}{\tau_{nNOS}} \left(  \frac{{{Ca^{2+}}^i}^3}{{{Ca^{2+}}^i}^3+1} - nNOS^i \right) \label{nNOS_dyn}\\
\dot{NO}(\mathbf{r},t)&=-\lambda NO + D \nabla^2 NO + \sum_{i} \delta^2(\mathbf{r}-\mathbf{r}_{neur}^i)\cdot nNOS^i \label{NO_dyn}\\
\dot{V_t^i}(t) &= \frac{NO(\mathbf{r}_{neur}^i,t)-NO_0}{NO_0\cdot\tau_{V_t}} \label{Theta_dyn}
\end{align}

A depolarization within a nerve cell upon a spike-event $t_{spike}$ causes a fixed inflow of ionic current $Ca^{2+}_{spike}$, which is modelled as an instantaneous increase of the $Ca^{2+}$ concentration. Over time, the concentration decays exponentially by a time constant $\tau_{Ca^{2+}}$, see \eqref{Ca_dyn}. Though $Ca^{2+}$ currents can be described in a much more detailed fashion, it can be considered as a reasonable approximation \cite[p.~198-203]{Theor_Neur_Dayan}. The aforementioned influence of $Ca^{2+}$ onto nNOS was modelled by Sweeney et al. through \eqref{nNOS_dyn}, using the Hill equation \cite{Hill_Equ} to model a cooperative binding mechanism. The $nNOS$ production is then fed into the "pool" of nitric oxide via point sources located at the neurons' positions. Apart from the inflow and the diffusive term $D \nabla^2 NO$, an additional decay term was added to provide a stable finite $NO$ concentration under constant neuronal activity.

Finally, the dynamics of the firing thresholds $V_t^i$ were modelled such that the rate of change is proportional to the relative deviation of the $NO$ concentration at the neurons' locations from a global target concentration $NO_0$. 

Obviously, the appropriate choice of $NO_0$ is crucial for the goal of achieving and maintaining a certain level of activity. However, one cannot directly set a parameter of the model to the desired population activity, as it was the case for canonical intrinsic homeostasis. Rather, one needs to determine the average concentration \textit{associated} with the desired activity and set it as a target concentration. Though it is possible to derive this relation in an analytic fashion, for practical purposes of the simulation, we let the system run with the previous homeostatic mechanism, still solving equation \eqref{Ca_dyn}-\eqref{NO_dyn} until a steady mean over the concentrations at the neurons' positions was reached. This mean was then set to be the target concentration and we switched to diffusive homeostasis. Table \ref{Params_IP} summarizes the choice of parameters that where introduced in this section.
\begin{table}
\begin{tabular}{|l|l|}
\hline
\textbf{parameter} & \textbf{value} \\
\hline
$\mathrm{r_{IP}}$ & $\mathrm{3\;Hz}$ \\
\hline
$\mathrm{\eta_{IP}}$ & $\mathrm{0.1\;mV}$ \\
\hline
$\mathrm{Ca^{2+}_{spike}}$ & 1 \\ \hline
$\mathrm{\tau_{Ca^{2+}}}$ &  $\mathrm{10\;ms}$ \\
\hline
$\mathrm{\tau_{nNOS}}$ & $\mathrm{100\;ms}$ \\
\hline
$\mathrm{D}$ & default: 12500 $\mathrm{\mu m^2 s^{-1}}$ \\
\hline 
$\mathrm{\lambda}$ & $\mathrm{0.1\;s^{-1}}$ \\
\hline
$\mathrm{\tau_{V_t}}$ & see section \ref{activ_analys} \\
\hline
\end{tabular}
\caption{Parameters of homeostatic intrinsic plasticity.}
\label{Params_IP}
\end{table}

\subsection{Simulation of Diffusion}

We solved \eqref{NO_dyn} with the finite difference method on a grid $\mathbf{r}_{i,j}$ with a resolution of $100\times 100$ points. Integration over time was carried out by a 4th-order Runge-Kutta method with a time step of $1 ms$. On each time step, $\nabla^2 NO(\mathbf{r}_{i,j}) = \nabla^2 NO_{i,j}$ was approximated by
\begin{equation}
\nabla^2 NO_{i,j} \approx \frac{NO_{i+1,j}+NO_{i-1,j}+NO_{i,j+1}+NO_{i,j-1}-4NO_{i,j}}{h^2}
\label{Laplace_Numeric}
\end{equation}
where $h = L/100$ is the distance between neighboured grid points, determined by the length $L$ of the square sheet and the resolution of the numeric grid. We implemented three possible boundary conditions into the simulation:

1.) Periodic boundary conditions:
\begin{align}
NO_{i,N+1} &= NO_{i,0} \label{Periodic_Cond_1} \\
NO_{N+1,i} &= NO_{0,i} \label{Periodic_Cond_2} \\
NO_{i,-1} &= NO_{i,N} \label{Periodic_Cond_3} \\
NO_{-1,i} &= NO_{N,i} \label{Periodic_Cond_4}
\end{align}
with $N$ being the grid resolution.

2.) Neumann boundary conditions, with $\nabla NO = (0,0)$ at the boundaries:
\begin{align}
NO_{i,N+1} &= NO_{i,N-1} \label{Neumann_Cond_1} \\
NO_{N+1,i} &= NO_{N-1,i} \label{Neumann_Cond_2} \\
NO_{i,-1} &= NO_{i,1} \label{Neumann_Cond_3} \\
NO_{-1,i} &= NO_{1,i} \label{Neumann_Cond_4}
\end{align}

3.) Dirichlet boundary conditions, with $NO = NO_{bound}$ at the boundaries.

If not explicitly marked differently, Neumann boundary conditions where used for most of the simulations. This decision relates to the previously described mechanism of synaptic growth: Neurons placed close to the edge of the sheet have a lower connection probability due to the absence of neighbouring neurons in the direction perpendicular to the close-by border. It therefore models the synaptic growth within a square "cutout" of neural tissue. The Neumann boundary condition fits into this picture, since it allows a zero-flux condition at the borders. This is a reasonable assumption, because NO molecules cannot diffuse out of the tissue (unless they were placed in a fluid surrounding).

Equation \eqref{NO_dyn} describes the influx of NO as a sum of scaled and spatially shifted Dirac functions. Apart from the question, whether this source term results in a well defined, finite solution at the neurons' positions (see section !!??!!), it can only be modelled to a certain degree of accuracy, depending on the resolution of the numeric grid. In practice, we approximated the point sources of NO as an insertions at individual grid cells at a rate of $nNOS^i(t) / h^2$, where the normalizing divisor $h^2$ ensured the desired total influx per neuron. This numeric implementation required two additional constraints: First, all random neuron positions were confined to integer multiples of $h$ in x- and y-direction. Second, to avoid redundancy and for physiological reasons, each grid cell could only hold one neuron at maximum. Both conditions combined led to an iterative generation of positions, where for each neuron a random number generator produced pairs of integers $(n_x,n_y)$, each within $[0,N]$, until an unoccupied pair of integers was found and occupied, moving on to the next neuron. Figure \ref{diff_test_plot} shows an example of the resulting NO density. 
\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.7\textwidth]{../../plots/density_plots/density_plot.png}
\end{center}
\caption{Example of NO-diffusion with 400 point sources of excitatory neurons.}
\label{diff_test_plot}
\end{figure}


\section{Results} \label{results}

Since our main goal of the implementation of diffusive homeostasis was to allow the network to develop a broader distribution of firing rates across excitatory neurons compared to the original version of homeostasis, we first present the results of a comparison between features of the network activity in both variants in section \ref{activ_analys}. Following this is an analytic discussion of an instability we observed within the diffusive homeostatic feedback loop, see section \ref{theor_osc}. Furthermore, we compare topological features of the network under the influence of diffusive and non-diffusive homeostasis in section ???. 

\subsection{Activity Analysis} \label{activ_analys}
As a first attempt, we set the time constant of threshold adaptation in the diffusive homeostasis to $\mathrm{2500\, ms}$, as given by \cite{Sweeney_Paper}. Switching between non-diffusive/diffusive homeostasis after 750 seconds, Figure \ref{full_sim_osci} shows the resulting dynamics of the population activity of the excitatory and inhibitory group, the average $NO$ concentration at the excitatory neurons' positions and the average firing threshold within the exc. group (inh. threshold was fixed, see table \ref{LIF_neuron_params}). Both homeostatic mechanisms managed to keep the excitatory population activity in the desired range of 3 Hz. However, what might appear to be slightly faster and stronger random fluctuations in the upper three plots of Figure \ref{full_sim_osci}, are in fact regular oscillations across all three depicted variables. While the oscillation amplitudes undergo a rather unpredictable time course, the frequency remains at a constant level of $\simeq 0.5\, Hz$. This feature is also illustrated by the fact that the power spectra depicted in Figure \ref{Power_Spec_without_Analysis} have a peak at the frequency that appeared to be dominant in Figure \ref{full_sim_osci}. The fact that the mean over all power spectra of excitatory thresholds differs from the power spectrum of the mean of these thresholds in its amplitude indicates that not all thresholds oscillate at the same phase. Still though, the overall shape of both spectra are equivalent. 
\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{../../plots/diff_hom/rate_NO_th_compl.png}
\end{center}
%\includegraphics[width=\textwidth]{../../plots/diff_hom/rate_NO_th_closeup.png}
\caption{A/A*: Mean of excitatory (blue) and inhibitory (red) neuronal firing rate. B/B*: NO concentration averaged over readouts at exc. neurons' positions. C/C*: Average exc. firing threshold. Non-diffusive homeostasis was used for $\mathrm{0-700\, s}$ , diffusive h. for $\mathrm{700-1500\, s}$. Target activity was $\mathrm{3\, Hz}$.}
\label{full_sim_osci}
\end{figure}
\begin{figure}
\begin{center}
%%% plot_pow_spec.py
\includegraphics[width=0.7\textwidth]{../../plots/power_spec/power_spectrum_sim_only.png}
\caption{Blue: Mean of power spectrum over all excitatory thresholds. Red: Power spectrum of mean over all exc. thresholds.}
\label{Power_Spec_without_Analysis}
\end{center}
\end{figure}
Although one might argue that - for the sake of practical purposes - regular oscillations of the $NO$ concentration are not of much concern for the network as such, a periodically fluctuating firing rate is a qualitative feature requiring further enquiry. Rhythmic patterns of activity are a commonly observed phenomenon within the brain. Depending on the rate of oscillations, the location within the brain and the spatial scale over which they are observed, different physiological features are found to be responsible, leading to explanatory models at different levels of abstraction. On a microscopic, single-neuron level, a so-called slow after-hyperpolarization conductance explains the appearance of bursting behaviour: A relatively short period of spiking activity is followed by a longer period of silence. This phenomenon can be modelled by a $Ca^{2+}$-dependent $K^{+}$-conductance. Upon the bursting period, $Ca^{2+}$ concentration rises, prohibiting continuous spiking due to the activation of $K^{+}$  current until the $Ca^{2+}$ concentration has returned to base-level \cite[p.~203-207]{Theor_Neur_Dayan}. However, due to the simplicity of our neuron model, this type of oscillating activity can be ruled out as an explanation.

On a larger, rate-based level, dynamical models of interconnected excitatory and inhibitory groups can exhibit sustained oscillations of activity \cite[p.~270]{Theor_Neur_Dayan}. As a simplest model, one can describe the dynamics of the exc. and inh. populations as a 2-dimensional dynamical system, representing the respective population rates $r_e$ and $r_i$:
\begin{align}
\tau_e \dot{r}_e  &= -r_e + \phi_e(r_e W_{ee} + r_i W_{ie}) \label{2d-exc_inh_rate_1} \\
\tau_i \dot{r}_i  &= -r_i + \phi_i(r_e W_{ei} + r_i W_{ii}) \label{2d-exc_inh_rate_2}
\end{align}

where $\tau_e$ and $\tau_i$ represents time constants representing the rapidity of firing rate adaptation, $\phi_e$ and $\phi_i$ the respective transition functions between synaptic input and firing rate and $W_{xy}$ the mean synaptic weight from population x to population y. A persistent oscillation then corresponds to a stable limit cycle in the 2-dimensional phase plane. According to the Poincaré-Bendixson Theorem, such a limit cycle exists inside a region $R$ if $R$ contains no fixed points and if any trajectory whose starting points lies within $R$ is confined to $R$. The second condition is equivalent to the condition that for all points $\mathbf{r}_{edge}$ on the edge of $R$, the vector field $\dot{\mathbf{r}}_{edge}$ is facing "into" $R$, see \cite[p.~248]{Dyn_Sys_Hirsch}. This case occurs if the system has a locally unstable fixed point, but a non-linearity that prevents an infinite deviation from the fixed point.
Coming back to the dynamics in question, one would need to show that the network has a locally unstable fixed point at $\mathrm{(r_e,r_i)\approx (3\, Hz, 13\, Hz)}$, see A* in Figure \ref{full_sim_osci}. Several aspects come into play, making it a hard task to fit the full spiking network model onto the simplified equations \ref{2d-exc_inh_rate_1} and \ref{2d-exc_inh_rate_2}. First, the choice of $\tau_e$ and $\tau_i$ in \ref{2d-exc_inh_rate_1} and \ref{2d-exc_inh_rate_2} has significant influence onto the stability of the system. However, a straightforward equivalent does not exist in the used spiking neuron model. It has been shown that in the case of slowly varying input $\tau_{e/i}$ of equation \ref{2d-exc_inh_rate_1} and \ref{2d-exc_inh_rate_2} are equal to the membrane constant $\tau_m$ of the LIF-neuron used in the network \cite{Gerstner_Pop_Act}, see equation \ref{LIF_Dynamics}. A second problem is to choose a good estimate of the activation functions $\phi_{e/i}( \cdot )$. In the absence of noise in equation \ref{LIF_Dynamics}, the firing rate for a given constant total input $J$ is
\begin{equation}
\phi(J) = \begin{cases}\frac{1}{-\tau_m ln(\frac{V_t -E_l-J\tau_m}{V_r -E_l-J\tau_m})} & \mathrm{for}\; J\tau_m + E_l > V_t\\
0 & \mathrm{otherwise}
\end{cases}.
\label{LIF_Fir_Rate_no_Noise}
\end{equation}
If noise $\sigma$ is present, according to \cite{Roxin_Firing_Rate_Distribution} one can calculate the \emph{mean} firing rate by
\begin{align}
\phi(J) &= \left[ \sqrt{\pi}\tau_m \int_{x_-}^{x_+} dx e^{x^2} erfc(-x) \right]^{-1} \label{LIF_Fir_Rate_with_Noise1}\\
x_- &= (V_r-E_l-J\tau_m)/\sigma \label{LIF_Fir_Rate_with_Noise2}\\
x_+ &= (V_t-E_l-J\tau_m)/\sigma \label{LIF_Fir_Rate_with_Noise3}
\end{align}
where $erfc$ is the complementary error function. Figure \ref{F-I_noise_dep} shows that both predictions are quite accurate in predicting the mean firing rate. 
\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{../../plots/F-I_noise_dep.png}
\end{center}
\caption{Comparison of mean firing rate of a LIF neuron without noise (squares) and with noise (circles, $\mathrm{\sigma = \sqrt{5}\, mV}$), averaged over $\mathrm{50\, s}$. Red and blue curves are the corresponding analytic predictions, see equation \ref{LIF_Fir_Rate_no_Noise} and \ref{LIF_Fir_Rate_with_Noise1}.}
\label{F-I_noise_dep}
\end{figure}
However, one should note that the synaptic input within a spiking network carries an intrinsic randomness: since it is the sum of instantaneous increases in membrane voltage upon arriving spikes, one cannot simply describe it as a mean constant input $J$. Rather, if we assume that the arrival of spikes is approximately poisson-distributed and the time constant of the membrane is small compared to the average interspike-interval, according to \cite{Roxin_Firing_Rate_Distribution}, one can describe the synaptic input from population $\mathrm{A}$ to population $\mathrm{B}$ as $J_{AB}(t) = \mu_{AB} (t) + \sigma_{AB} \cdot \zeta(t)$, where $\zeta(t)$ is zero-mean standard gaussian noise and
\begin{align}
\mu_{AB} &= <w_{AB}> \cdot <N_{in,AB}> \cdot <r_A> \label{Noise_Approx_1}\\
\sigma_{AB} &= \sqrt{\tau_m \cdot <w_{AB}>^2 \cdot <N_{in,AB}> \cdot <r_A>} \label{Noise_Approx_2} \, .
\end{align}
$\mathrm{<w_{AB}>,\, <N_{in,AB}>}$ and $\mathrm{<r_A>}$ denote the mean weight of a synapse connection population $\mathrm{A}$ with population $\mathrm{B}$, the mean number of incoming connections at a neuron in population $\mathrm{B}$ and the mean firing rate in population $\mathrm{A}$ (which makes it necessary to assume changes within the firing rate to be slow enough for a quasi-stationary description of the activity).
Since we can assume intrinsic and input noise to be uncorrelated, the total noise within a neuron of population $\mathrm{B}$ has a standard deviation of 
\begin{equation}
\sigma_{tot.} = \sqrt{\sigma_{intr.}^2 + \sum_A \sigma_{AB}^2} \; .
\label{Total_Noise_Neuron}
\end{equation}

Apart from the correct description of $\phi_{e/i}$, a third problem is the analytic description of the STP that was present for recurrent excitatory connections in our network. In \cite{Markram_STP}, the steady-state value of $\mathrm{x\cdot u}$ for an input of constant rate $\mathrm{r}$ is given by
\begin{align}
x_{st.}(r) &= \frac{1-\exp \left(-\frac{1}{r\cdot \tau _d}\right)}{1-\left(1-u_{st.}\left(r\right)\right)\cdot \exp \left(-\frac{1}{r\cdot \tau _d}\right)} \label{STP_steady1} \\
u_{st.}(r) &= \frac{U}{1-\left(1-U\right)\exp \left(-\frac{1}{r\cdot \tau _f}\right)} \; .\label{STP_steady2}
\end{align}
When trying to find the fixed point of equations \ref{2d-exc_inh_rate_1} and \ref{2d-exc_inh_rate_2}, one thus needs to incorporate the factor $\mathrm{x_{st.}\cdot u_{st.}}$ by means of the previously described mean input and the contribution to the total variance of the membrane noise.
 
All these aspects taken together make it impossible to find an analytic expression for the fixed point of Equation \ref{2d-exc_inh_rate_1} and \ref{2d-exc_inh_rate_2}. Running a simulation of \ref{2d-exc_inh_rate_1} and \ref{2d-exc_inh_rate_2}, including all aforementioned approximations results in a stable configuration depicted in \ref{Dyn_Rate_Approx}. For this simulation, we set the relevant parameters to their predefined values and, in addition, extracted the mean threshold of the excitatory population which was set by the non-diffusive homeostasis, see C/C* in Figure \ref{full_sim_osci}, yielding a threshold of $\mathrm{-56.963\, mV}$. The results are depicted in Figure \ref{Dyn_Rate_Approx}. The system settled to a fixed point of $\mathrm{(r_{0,e},r_{0,i}) = (2.992\, Hz, 7.144\, Hz)}$, which is quite close to $\mathrm{(3\, Hz, 6.768\, Hz)}$, being the mean excitatory and inhibitory firing rate between 100-750 s of the full simulation (i.e., during non-diffusive homeostasis).
\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{../../plots/approx_rates_EI.png}
\end{center}
\caption{Dynamics of equations \ref{2d-exc_inh_rate_1} (blue line) and \ref{2d-exc_inh_rate_2} (red line). Dotted lines mark the mean frequencies that where present in the full spiking network. Excitatory: 3 Hz, Inhibitory: 6,768 Hz. \ref{2d-exc_inh_rate_1} and \ref{2d-exc_inh_rate_2} converged to 2.992 Hz and 7.144 Hz respectively.}
\label{Dyn_Rate_Approx}
\end{figure}
In principal, one could now further quantify the stability of the found fixed point by calculating the Jacobian matrix at $\mathrm{(r_{0,e},r_{0,i})}$. For the sake of the initial question though, namely the source of oscillation, it is sufficient at this point to restrict oneself to a preliminary result: Assuming validity of the described rate-model, the recurrent network as such (without homeostasis) is stable under the given choice of parameters. Furthermore, on an empirical basis, the occurrence of oscillations appear to be rather dependent on the choice of homeostasis, since apart from the homeostatic mechanism itself, all parameters of the simulation were kept unchanged upon the transition after 750s. In consequence, the following section further analyzes the dynamics underlying the diffusive homeostatic feedback.

\subsection{Analysis of Oscillations under Dynamic Feedback}\label{theor_osc}
In this section, we discuss an analytic treatment of the dynamics underlying the diffusive homeostatic mechanism. The goal of this analysis was to predict the shape of the power spectrum shown in Figure \ref{Power_Spec_without_Analysis}. This gave insight into the relation between parameters of the model and the resulting preferred frequency and amplitude, allowing us to choose appropriate parameter values in order to reduce frequency and amplitude of the oscillations.

Both forms of homeostasis use excitatory firing thresholds as a means of adjusting the excitatory firing rate. Though having a relatively immediate impact on the firing rate of the particular neuron, the network as a whole reacts by means of a local disturbance of activity as well: it settles at a new fixed point of firing rates. Two questions are of importance in the context of feedback dynamics. First - obviously - how the relation between a local change of threshold and the new fixed point of the network can be described and second, whether the time scale of the network's response is of relevance with respect to other time scales involved in the feedback loop. Regarding the second question, Figure \ref{rate_th_close} suggests that the excitatory population activity follows the mean firing threshold in a quasi instantaneous fashion, at least in comparison with the overall time scale of the oscillating pattern.
\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{../../plots/diff_hom/rate_th_close.png}
\end{center}
\caption{Time course of the mean firing rate (blue) and the mean firing threshold within the excitatory pool (red). Bin width for firing rate estimation was 0.1 s.}
\label{rate_th_close}
\end{figure}
Thus, in a first attempt of understanding the occurrence of undesired oscillations, we presumed an immediate functional relationship $\mathbf{r}_e (t) = \mathbf{r}_e (\mathbf{V}_{t,e} (t))$, $\mathbf{r}_e$ and $\mathbf{V}_{t,e}$ representing the set of excitatory firing rates and thresholds, respectively.

Describing the neural activity as instantaneous firing rates raises the question how to describe the production of nitric oxide, since the outcome of equations \eqref{Ca_dyn} and \eqref{nNOS_dyn} relies on sudden increases of $Ca^{2+}$ concentration caused by spike events. Naively, one could replace the sum of dirac functions in \eqref{Ca_dyn} by a continuous inflow $Ca^{2+}_{spike} r_i(t)$. If \eqref{nNOS_dyn} was a linear homogeneous differential equation, this approximation would indeed allow for the correct calculation of a linear relation between mean firing rate and NO production. The cubic dependence on $Ca^{2+}$ breaks this simplicity. In order to derive an approximate description, we denote two things: First, the target firing rate of 3 Hz and the corresponding mean interspike interval of 0.33...s is large compared to the decay constant of Calcium, $\tau_{Ca^{2+}} = \mathrm{0.01\,s}$. Consequently, it is very unlikely that one spike event will fall into a region where the Calcium concentration, decaying from the instant jump of the previous spike event, is still significantly larger than zero. As such, one can justify
\begin{equation}
\begin{split}
{Ca^{2+}}^3(t) &= \left[ Ca^{2+}_{spike} \sum_{i} \theta(t-t^i_{spike,i}) exp(-(t-t^i_{spike,j})/\tau_{Ca^{2+}}) \right]^3 \\
&\approx {Ca^{2+}_{spike}}^3 \sum_{i} \theta(t-t^i_{spike,i}) exp(-3(t-t^i_{spike,j})/\tau_{Ca^{2+}})
\end{split} \label{cubic_approx_1}			
\end{equation}
with $\theta(x)$ being the Heaviside step function. By the same argument
\begin{equation}
\frac{{Ca^{2+}}^3(t)}{{Ca^{2+}}^3(t)+1} \approx \sum_{i} \theta(t-t^i_{spike}) \frac{exp(-3(t-t^i_{spike})/\tau_{Ca^{2+}})}{exp(-3(t-t^i_{spike})/\tau_{Ca^{2+}}) + \frac{1}{{Ca^{2+}_{spike}}^3}}  
\end{equation}
Therefore, the resulting rate of NO synthesis can be decomposed into a sum of time shifted responses onto a single kernel of Calcium concentration as a result of a spike. for a spike at $t_{spike}=0$, the solution of \eqref{nNOS_dyn} can be calculated by
\begin{equation}
\begin{split}
nNOS(t) &= \frac{1}{\tau_{nNOS}}\int_{-\infty}^t dt' exp(-(t-t')/\tau_{nNOS})\cdot \theta(t') \frac{exp(-3t'/\tau_{Ca^{2+}})}{exp(-3t'/\tau_{Ca^{2+}}) + \frac{1}{{Ca^{2+}_{spike}}^3}} \\
&= \frac{1}{\tau_{nNOS}}\int_{0}^t dt' exp(-(t-t')/\tau_{nNOS})\cdot \frac{exp(-3t'/\tau_{Ca^{2+}})}{exp(-3t'/\tau_{Ca^{2+}}) + \frac{1}{{Ca^{2+}_{spike}}^3}}\;.
\end{split}\label{nNOS_single_sol}
\end{equation}
The exact solution of this integral can be expressed in terms of the hypergeometric function, making it rather impractical for any further analysis. Looking for further simplifications, we note that $\tau_{nNOS}$ is chosen ten-fold larger than $\tau_{Ca^{2+}}$. This discrepancy in decay times allows for the assumption that the impact of the Calcium kernel onto $nNOS$ is practically instantaneous. Consequently, $nNOS(t)$ becomes
\begin{equation}
nNOS(t) = \frac{1}{\tau_{nNOS}} \theta(t) exp(-t/\tau_{nNOS}) \int_{0}^\infty dt' \frac{exp(-3t'/\tau_{Ca^{2+}})}{exp(-3t'/\tau_{Ca^{2+}}) + \frac{1}{{Ca^{2+}_{spike}}^3}}\;.
\label{nNOS_single_sol_approx1}
\end{equation}
In this form, the integral has an easy-to-handle solution, which - with all spike events now included - results in
\begin{equation}
nNOS(t) = \frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3\tau_{nNOS}} \sum_i \theta(t-t^i_{spike}) \exp(-(t-t^i_{spike})/\tau_{nNOS})\;.
\label{nNOS_single_sol_approx2}
\end{equation}
Figure \ref{nNOS_approx_plot} compares the approximation given by \eqref{nNOS_single_sol_approx2} to the full NO production model (equations \eqref{Ca_dyn} and \eqref{nNOS_dyn}). Spikes were drawn from a poisson process at a rate of 3 Hz. As predicted, the simplified model fits very well for sufficiently isolated spike events. For the rare event of two subsequent spikes appearing very close to each other, as seen in Figure \ref{nNOS_approx_plot} at approximately 4 seconds, one can observe a slightly smaller but acceptable agreement.
\begin{figure}
%%% ca_nnos_test.py
\includegraphics[width=\textwidth]{../../plots/nNOS_approx.png}
\caption{Time course of nNOS(t) with poisson spiking at 3Hz. The full simulation (blue, see equations \eqref{Ca_dyn},\eqref{nNOS_dyn}) is well fitted by the simplified model (red, see equation \eqref{nNOS_single_sol_approx2}). Top axis is a closeup of the first spike event.}
\label{nNOS_approx_plot}
\end{figure}

Returning to the question of how to describe NO synthesis in a simplified form, we note that according to equation \eqref{nNOS_single_sol_approx2}, a single spike causes the release of NO by an amount of $\frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3}$, which makes the mean rate of NO production over time simply $<nNOS> = <r> \cdot \frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3}$. However, it is not sufficient to simply propose $nNOS_i(t) = r_i(t) \cdot \frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3}$. A single cell fires in the range of $\mathrm{3\,Hz}$, which is - at least on the time scale of the observed oscillations - not enough to assign an "instantaneous" firing rate.

To deal with this, we introduce an idealized picture of diffusive homeostasis, where diffusion across the tissue is instantaneous. This simplification results in a single level of NO-concentration for all neurons, only being modified over time by the sum of all neurons' NO-syntheses $nNOS_{total}(t) \equiv \sum_{i} nNOS^i(t)$ and the decay term $-\lambda NO$. To account for the spread of NO, $nNOS_{total}$ must be divided by the area $L^2$ of the tissue. Furthermore, we introduce a random fluctuation term $\sigma_{NO} \xi(t)$ that accounts for local, momentary deviations from the mean. The idealized version of \eqref{NO_dyn} then reads
\begin{equation}
\dot{NO}(t)=-\lambda NO + \frac{nNOS_{total}(t)}{L^2} + \sigma_{NO} \xi(t)\;.
\label{NO_dyn_approx}
\end{equation}
The amount of noise in the system is a hard-to-predict quantity since it depends on the spatial structure on the diffusive lattice, giving neurons that are further separated less impact on each other. We tried to estimate the noise level based on the same "instant spread"-simplification made in Equation \eqref{NO_dyn_approx} to describe the overall NO-dynamics. In the final result, this led to an underestimation of the total energy within the power spectrum. However, as long as we assume the noise in the system to be approximately white, noise level only acts as a global scaling factor of the shape of the power spectrum and was thus left open as a model fitting parameter.

From Equation \eqref{NO_dyn_approx} it is clear why we can now describe the \emph{total} influx of NO as the sum of a mean and a random fluctuation: While spiking events on individual cells remain sufficiently separated to justify equation \eqref{nNOS_single_sol_approx2}, the sum of all spike events from the excitatory population results in an effective poisson process with a mean rate of $3 Hz \cdot N_{exc.} = \mathrm{1200\,Hz}$, given the assumption that cells are spiking weakly correlated. Furthermore, we argue that a total rate of $\mathrm{1200\,Hz}$ is sufficiently large to express this rate as a continuous function of time, $r_{total} = N_{exc.}\cdot r_{exc.pop.}(t)$, at least on the time scale of the oscillations to be studied (see  Figure \ref{rate_th_close}). We thus propose
\begin{equation}
nNOS_{total}(t) = r_{exc.pop.}\cdot N_{exc.}\frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3}
\label{nNOS_total_dyn}
\end{equation} 
where $\frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3}$ is the integral from Equation \eqref{nNOS_single_sol_approx1}.

As a next step, we wanted to simplify the dynamics of threshold adaption and its effect on the population rate. Corresponding to the reduction to a single variable $r_{exc.pop.}(t)$ for the mean excitatory activity in equation \eqref{nNOS_total_dyn}, we wanted to find an appropriate description containing only the mean threshold $V_{t,pop.}(t) = <V_t(t)>$. As stated earlier, Figure \ref{rate_th_close} suggests an immediate and approximately linear relation between excitatory population rate and the mean of thresholds within the excitatory population. Figure \ref{thresh_r_linfit} shows a linear fit (being of the form $\alpha x + \beta$) of these two quantities plotted against each other. Apart from rarely appearing high values of $V_{t,pop.}$, we found a good fit to the linear model. We thus expressed the population rate by $r_{exc.pop.}(t) = r_{IP} + \alpha(V_{t,pop.}(t)-V_{t,0})$, where $r_{IP}$ is given in table \ref{Params_IP} as the mean excitatory target firing rate and $V_{t,0} \equiv (r_{IP}-\beta)/\alpha$ is the mean threshold corresponding to the target rate.
\begin{figure}
%%% linfit_th_rate.py
\includegraphics[width=\textwidth]{../../plots/Spike_Stats/linfit_th_rate.png}
\caption{Linear fit of excitatory population activity and mean excitatory threshold. Slope $\alpha$ of the fit: $\mathrm{-0.789\, Hz/mV}$. Offset $\beta$: $\mathrm{-41.97\, Hz}$. Mean squared error: $\mathrm{R^2 = 0.68}$.}
\label{thresh_r_linfit}
\end{figure}

Combining these results in a set of equations, we find
\begin{align}
\dot{NO}(t) &= -\lambda NO + \frac{(r_{IP} + \alpha(V_{t,pop.}(t)-V_{t,0}))\cdot N_{exc.}\frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3}}{L^2} + \sigma_{NO} \xi(t) \label{2d-sys-homeostasis1}\\
\dot{V_{t,pop.}}(t) &= \frac{NO-NO_0}{NO_0 \tau_{V_t}}\;. \label{2d-sys-homeostasis2}
\end{align}
Through the coordinate transformations
\begin{align}
n &\equiv NO-NO_0 \label{simplif_coord_transf1}\\
\theta &\equiv V_{t,pop.}(t)-V_{t,0} \label{simplif_coord_transf2}\\
\end{align}
we can simplify the dynamical system:
\begin{align}
\dot{n} &= -\lambda n + \frac{\gamma \alpha N_{exc.}}{L^2}\theta + \sigma_{NO} \xi(t) \label{2d-sys-homeostasis-coord_transf1}\\
\dot{\theta} &= \frac{1}{NO_0 \tau_{V_t}} n \label{2d-sys-homeostasis-coord_transf2}
\end{align}
where we have additionally used
\begin{align}
\gamma &\equiv \frac{{Ca^{2+}_{spike}}^3 \tau_{Ca^{2+}}ln(2)}{3} \label{2d-sys-fixed-points1}\\
NO_0 &= \frac{nNOS_{total,0}}{\lambda L^2} \label{2d-sys-fixed-points2}\\
nNOS_{total,0} &= r_{IP}\cdot N_{exc.} \cdot \gamma \; . \label{2d-sys-fixed-points3}
\end{align}
As stated in the beginning, we were interested in finding an analytic expression for the power spectrum of the mean excitatory threshold. Therefore we took the fourier transform of \eqref{2d-sys-homeostasis-coord_transf1} and \eqref{2d-sys-homeostasis-coord_transf2}, yielding
\begin{align}
i\omega f_n &= - \lambda f_n + \frac{\gamma \alpha N_{exc.}}{L^2}f_\theta + \sigma_{NO} f_{\xi} \label{2d-sys-homeostasis-coord_transf_ft1}\\
i\omega f_\theta &= \frac{f_n}{NO_0\tau_{V_t}} \label{2d-sys-homeostasis-coord_transf_ft2} \\
\end{align}
where $f_{(\cdot)}$ denotes the fourier transform. We solved for $f_\theta$ which immediately gave us the power spectrum $P_\theta (\omega) \equiv |f_\theta (\omega)|^2$ of $\theta$:
\begin{equation}
P_\theta (\omega) = \frac{\sigma_{NO}^2}{\omega^2 NO_0^2 \tau_{V_t}^2 \lambda^2 + \left( \omega^2 NO_0 \tau_{V_t} + \frac{\gamma \alpha N_{exc.}}{L^2}\right)^2} \label{Pow_Spec_Theta_Final}
\end{equation}
Since we assumed the noise term $\xi$ to be approximately white and gaussian noise with unit variance, its power spectrum is $|f_{\xi}|^2 = 1$.

Figure \ref{Pow_Spec_Theta_vs_Analytic} shows the result of \eqref{Pow_Spec_Theta_Final}. Choosing noise amplitude to be the only free parameter of the model gave a rather unsatisfying result. Our approximation underestimated the amount of damping within the system (which controls the "peakiness" of the spectrum), as well as predicting a slightly smaller preferred amplitude. While the broadness of the spectrum is mostly controlled by the damping term $-\lambda$, the preferred amplitude is controlled by $\frac{\gamma \alpha N_{exc.}}{L^2}$ and $\frac{1}{NO_0\tau_{V_t}}$. Since the latter term was taken unaltered from the original system (apart from a shift in phase space), we added $-\lambda$ and $\alpha$ as free fitting parameters and managed to get a very good fit to the simulation data, see Figure \ref{Pow_Spec_Theta_vs_Analytic}.   
\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{../../plots/power_spec/power_spectrum_analytic.png}
\end{center}
\caption{Power Spectrum of $\mathrm{\langle V_t \rangle}$ (blue) and analytic predictions based on Equation \eqref{Pow_Spec_Theta_Final}. Red curve was fitted by tweaking only the overall amplitude $\mathrm{\sigma_{NO}}$ in \eqref{Pow_Spec_Theta_Final} ($\mathrm{\alpha = -0.789 \,Hz/mV}$, as in Figure \ref{thresh_r_linfit}). Green curve is a fit achieved by adjusting $\mathrm{\sigma_{NO}}$ and $\mathrm{\lambda}$ in \eqref{Pow_Spec_Theta_Final} ($\mathrm{\lambda = 0.845 \,s^{-1}}$). Black curve was fitted by means of $\mathrm{\sigma_{NO}}$, $\mathrm{\lambda}$ and $\mathrm{\alpha}$ ($\mathrm{\lambda = 0.592 \,s^{-1}}$, $\mathrm{\alpha=-0.989 \,Hz/mV}$).}
\label{Pow_Spec_Theta_vs_Analytic}
\end{figure}
The fact that the value for $\mathrm{\alpha}$ that was determined by means of the linear fit in Figure \ref{thresh_r_linfit} leads to an underestimation of the preferred frequency can be partially explained by the fact that the linear regression overestimates the importance of a number of high-threshold-outliers which leads to a shallower slope than what would be appropriate for the "working point" of oscillatory behaviour. Another possible explanation is the fact that "instant spread" is only an approximation. Rather, one could picture the nitrous oxide just to fill a fraction of the available space on a short time scale by replacing $L^2$ by a smaller area. This leads to a stronger local increase of concentration, which eventually leads to faster oscillations. In either case, since these parameters appear as a fraction $\alpha/L^2$ in \eqref{Pow_Spec_Theta_Final}, both parameters have the same effect onto the shape of the power spectrum.

Regarding the damping of the system, we can interpret   !!! SIMULATION STEHT NOCH AUS!!! 

In the context of the presented power spectra, reducing oscillations meant to reduce height and frequency of the peak of the spectrum. We managed to do so by increasing the time constant $\mathrm{\tau_{V_t}}$, as shown in Figure \ref{Peak_Prop_vs_Theta}. Moreover, by choosing $\mathrm{\sigma_{NO}}$, $\mathrm{\lambda}$ and $\mathrm{\alpha}$ in accordance to the fit shown in Figure \ref{Pow_Spec_Theta_vs_Analytic} (black curve), Equation \eqref{Pow_Spec_Theta_Final} provides a good prediction for the position and height of the peak. For proper comparison, we smoothed the curve of the simulation data in plot (A) of Figure \ref{Peak_Prop_vs_Theta} by a window of $\mathrm{[-5,5]}$ data points, since the maximum of the power spectrum of simulation data is likely to overshoot the analytic prediction due to random fluctuations.  
\begin{figure}
%%% plot_osc_ampl_vs_tau_theta.py
\includegraphics[width=\textwidth]{../../plots/diff_hom/osc_ampl_vs_tau_th.png}
\caption{A: Maximum of the spectrum-peak (see Figure \ref{Pow_Spec_Theta_vs_Analytic}). A smoothing window of $\mathrm{[-5,5]}$ data points around the maximum was used to reduce overestimation of the maximum due to random fluctuations. Blue line corresponds to Equation \eqref{Pow_Spec_Theta_Final}, fit values taken from black curve in Figure \ref{Pow_Spec_Theta_vs_Analytic}. B: Position of the peak on the frequency axis. Analytic prediction was acquired according to (A).}
\label{Peak_Prop_vs_Theta}
\end{figure} 
To reduce oscillations as much as possible we eventually settled at a 1000-fold increased time constant, $\mathrm{\tau_{V_t}=2500\,s}$. Despite the slowness of threshold adaption, homeostasis still managed to keep excitatory network activity in the desired range, as shown in Figure \ref{full_sim_osci_slow_tau_th}. Despite a slight regularity of the NO-concentration, no oscillating activity occurs.  
\begin{figure}
%%% oscillating_activity_plot_full_time_only.py
\includegraphics[width=\textwidth]{../../plots/diff_hom/rate_NO_th_compl_large_tau.png}
\caption{A: Excitatory (blue) and and inhibitory (red) population rate, being controlled by diffusive homeostasis over the full simulation time. B,C: Mean NO-concentration over excitatory sites and mean excitatory threshold.}
\label{full_sim_osci_slow_tau_th}
\end{figure}
We took this setting as a basis for further analysis of network activity.

\subsection{Properties of Network Activity}

After the elimination of oscillatory activity in the network, we further investigated the features of neural activity, in particular of the excitatory population, since it was exposed to homeostasis. This includes statistics of spike timing, as well as of heterogeneous firing rates among the network.  

\subsubsection{Spike-Train Statistics}
Balanced networks of inhibitory and excitatory populations of spiking LIF-neurons are known to show highly random, uncorrelated spiking behaviour under sparse connectivity with a relatively high per-synapse connection strength, see e.g. \cite{Vreeswijk1996} or \cite{Brunel2000}. This kind of asynchronous regular state is characterized by a population firing rate showing no regularities over time, though maintaining an overall stable level of activity. This feature was shown in the previous section after slowing down the rate of homeostatic adaption. On the level of single cells, interspike intervals should be random, approximately following the statistics of a poisson process.   
\begin{figure}
%%% isi_plot.py
\includegraphics[width=\textwidth]{../../plots/Spike_Stats/isi_cv_compare.png}
\caption{A/C: Distribution of interspike intervals of excitatory/inhibitory neurons for diffusive and non-diffusive homeostasis, measured over $\mathrm{1000\,s}$. Only neurons with a mean firing rate in a certain range (see legend) were included into statistics to prevent overlap of different firing rates (except for non-diff. homeostasis and excitatory neurons, all being very close to 3 Hz). Black lines are fits of exponential functions. B/D: Distribution of coefficients of variation. Each sample represents the CV of one excitatory/inhibitory neuron.}
\label{ISI_CV_compare}
\end{figure}
Figure \ref{ISI_CV_compare} shows the distribution of interspike intervals (ISIs) and the distribution of coefficient of variation ($\mathrm{CV\equiv\sigma/\mu}$), taken over the set of excitatory and inhibitory neurons. However, in order to provide comparability between the ISI distributions in the diffusive/non-diffusive case, we restricted the statistics of ISIs to neurons whose mean firing rate fall into a window with a width of 1 Hz and a certain mean (see legend in Figure \ref{ISI_CV_compare}). Apparently, an approximately exponential distribution of ISIs is preserved for diffusive homeostasis (represented by straight lines in a log-plot), which is characteristic for poisson processes \cite[p. 27]{Theor_Neur_Dayan}. For perfect poissonian spiking, the CV should give a value of 1. CVs that are smaller/larger, as seen in Figure \ref{ISI_CV_compare} B/D, indicate a tendency towards greater/less regularity. This is presumably due to the statistics of ISIs close to zero: Interestingly, while excitatory neurons have an  under-representation of short ISIs, the opposite is the case for inhibitory neurons. These types of behaviour of LIF-models have been shown to depend on the CV of input the neuron receives \cite{Ostojic2011}: A smaller signal-to-noise-ratio (larger CV) of neural input leads to a larger CV of ISIs for the output and an over-representation of small intervals. This relation fits nicely into our set of network parameters: inhibitory neurons receive stronger recurrent inhibitory input ($\mathrm{-60\,mV}$ in total) compared to excitatory neurons ($\mathrm{-12\,mV}$). This lowers the signal-to-noise ratio for the inputs of inhibitory neurons, leading to the aforementioned statistical differences. Still, one can observe a dominant exponential component for both excitatory and inhibitory neurons.

As an additional possibility of spike-train analysis, we looked at potential correlations across neurons within both populations. To do so, we calculated cross-correlations for all possible neuron-pairings within a population, excluding auto-correlations. Figure \ref{Pop_Mean_Cross_Corr} shows the mean cross-correlation taken over all these pairs. Surprisingly, we found a significant increase in correlation across neurons for diffusive homeostasis. 
\begin{figure}
\includegraphics[width=\textwidth]{../../plots/Spike_Stats/pop_mean_cross_corr.png}
\caption{Mean of cross correlation over all pairs of neurons in the respective neuron-group. Significantly higher correlation can be found in both groups for diffusive homeostasis. Spike data was taken from $\mathrm{1400-1500\,s}$ of the simulation.}
\label{Pop_Mean_Cross_Corr}
\end{figure}
When speculating about the root of this discrepancy one could consider two possibilities: either, it is an immediate consequence of diffusive homeostasis, or it is indirectly related through other mechanisms present within the network. Regarding the first, it is certainly true that some amount of information about the activity of one neuron is transferred to another one in its neighbourhood via diffusion. However, due to the time scale of the homeostatic adaption, the response to fluctuations in the diffusive signal is on the order of seconds, while correlations in Figure \ref{Pop_Mean_Cross_Corr} are taking place within milliseconds. Thus, we concluded that a \emph{direct} link between homeostatic signalling and increased correlations can be regarded as implausible and that it must be an effect based on topological differences within the network. We investigate these in Section (???).

In summary, we found that diffusive homeostasis does not interfere with the poisson-like spiking statistics observed on a single-cell level, but leads to an increased correlation across the neural population. 

\subsubsection{Distribution of Firing Rates}
Achieving a broad distribution of firing rates among neurons was the core motivation for the implementation of diffusive homeostasis. Figure \ref{Fir_Rate_Dist_Compare} shows a first result, comparing both homeostatic mechanisms. As expected, non-diffusive homeostasis leads to a sharp distribution of firing rates at 3 Hz. Diffusive homeostasis indeed results in a much broader distribution of mean firing rates. A large number of experimental studies have found that distributions of firing rates are not only broadly distributed but well described by a log-normal distribution, which has a non-zero third moment or skewness (\cite{Buzsaki_Fir_Rates_2014}, \cite{Wohrer_Fir_Rates_2012}). By definition, the logarithm of the random variable in question is thus again normally distributed. To check for this property we plotted the the distribution of decadic logarithms of firing rates in Figure \ref{Fir_Rate_Dist_Compare} (B). In (A), we found a skewness of $\mathrm{v_{Diff} = 0.765}$, in (B) $\mathrm{v_{Diff,log} = -0.488}$. Though this told us that the distribution is "more symmetric" on a logarithmic scale, it should rather be seen as being neither strictly normally or log-normally distributed.  
\begin{figure}
%%% plot_frequ_dist_mult_sets.py
\includegraphics[width=\textwidth]{../../plots/firing_rate_dists/fir_rate_dist_e_compare.png}
\includegraphics[width=\textwidth]{../../plots/firing_rate_dists/fir_rate_dist_i_compare.png}
\caption{Histograms of mean firing rates over the excitatory/inhibitory population in regular (A/A*) and logarithmic space (B/B*). For diffusive homeostasis ($\mathrm{D=1000\, \mu m^2 s^{-1}}$), the distribution was generated from 10 simulation runs, 1 simulation was used for non-diffusive homeostasis. Mean firing rates where calculated from spikes within $\mathrm{t=1000-1500\,s}$.}
\label{Fir_Rate_Dist_Compare}
\end{figure}
In contrast, inhibitory cells showed a much clearer distinction: A skewness of $\mathrm{v_{Diff} = 1.522}$ in regular space and $\mathrm{v_{Diff,log} = -0.147}$ in log-space. As a first interpretation, we related this difference to the fact that inhibitory cells are only indirectly affected by diffusive homeostasis in the sense that their distribution of activity is mainly determined by differences withing neural input while inhibitory thresholds are all initialized and kept at the same value.

Despite of fluctuations within the firing rate on small time scales due to the inherent nature of - approximately - random spike generation, we wanted to know how strongly firing rates of single excitatory cells fluctuate over longer timescales of multiple seconds. This question is not only of relevance with respect to the "stiffness" of homeostasis, but also relates to the plot in Figure \ref{Fir_Rate_Dist_Compare}: if firing rates fluctuate too much during the period over which means were calculated, the resulting distribution might be narrower than what one could expect from a distribution of "momentary" rates.

A constant "rate" of an approximately randomly spiking neuron means that the dependence of fluctuations of rates onto the width of the averaging window should be identical to a homogeneous poisson process of the same total mean firing rate. As bin sizes increase, possible long-term fluctuations of firing rates can then be identified as deviations from the variance one would expect from a homogeneous process. We tested this in Figure \ref{f_Var_vs_n_Bin}. (A) was taken from $\mathrm{1000-1500\,s}$, which is well inside the phase of diffusive homeostasis. As one can see, the statistics of the three representative neurons are well fitted by the predictions for homogeneous poisson processes with the same mean rate, being a straight line given by $\mathrm{var = f_{mean}\cdot n_{bins}/T_{total}}$, though slight deviations can be seen as a different factor of proportionality. (B) acts as an illustration showing a counterexample: here, we included the entire time span of the simulation, including the transition between non-diffusive and diffusive homeostasis. For almost all of the neurons, this will cause a transition of firing rate between 3 Hz and a new rate different from 3 Hz. This inhomogeneity is represented by the increasing positive relative deviation from the dashed line for small number of bins (i.e., large bin widths), even increasing again for a very few number of bins.
\begin{figure}
%%% plot_spt_var_vs_bin_width.py
\includegraphics[width=\textwidth]{../../plots/Spike_Stats/sim_f_var_vs_hom_poisson.png}
\caption{A: Relation between Variance of the frequency signal (acquired by binning spikes) and the number of bins within the given time range of $\mathrm{1000-1500\,s}$, taken from three randomly picked excitatory neurons. B: Same procedure as in (A) for a randomly chosen excitatory neuron, but time range was $\mathrm{1000-1500\,s}$, which includes the initial phase of non-diffusive homeostasis. In both plots, dashed lines are the expected curve of a homogeneous poisson process of the same mean rate.}
\label{f_Var_vs_n_Bin}
\end{figure}
We therefore concluded that diffusive homeostasis manages to retain firing rates on a constant level, not only population-wise but on a single-cell level as well. In particular, plastic modifications across the network due to STDP and synaptic growth/pruning - which where always acting for all the simulation results presented so far - appeared to be compensated for.

Sweeney et al. found that diffusive homeostasis maintains broadness of firing rates across a wide range of diffusion constants but rapidly approaching zero for small values \cite[p. 6]{Sweeney_Paper}. We were able to reproduce this result, see Figure \ref{Fir_Rate_Dist_Width_vs_D}. Homeostasis reaches a point of saturation, where faster diffusion has no effect on the heterogeneity of firing rates. 
\begin{figure}
%%% freq_dist_width_vs_D.py
\includegraphics[width=\textwidth]{../../plots/firing_rate_dists/std_dev_vs_D_neumann.png}
\caption{Standard deviation of firing rate distribution of excitatory neurons (neumann boundary conditions).}
\label{Fir_Rate_Dist_Width_vs_D}
\end{figure}
To further quantify this dependence, we also investigated the influence of the diffusion constant onto the distribution's skewness, shown in Figure \ref{Fir_Rate_Dist_Skew_vs_D}. Compared to the standard deviation, we see a similar but not as clear trend with a drop for very small diffusion constants, even occasionally resulting in a left-skewed distribution (negative D-values).
\begin{figure}
%%% freq_dist_skew_vs_D.py
\includegraphics[width=\textwidth]{../../plots/firing_rate_dists/skew_vs_D_neumann.png}
\caption{Skewness of firing rate distribution of excitatory neurons (neumann boundary conditions).}
\label{Fir_Rate_Dist_Skew_vs_D}
\end{figure}
A naturally emerging question when altering the diffusion constant is how the firing rate behaves in the absolute limit of infinitely fast diffusion. In fact, simulation-wise this case is quite easy to simulate: one simply has  to feed all NO-sources into a single scalar variable of NO concentration. In particular, this will provide the same NO readout for all excitatory neurons, which means that all excitatory thresholds change at the same rate all the time, only shifting their initial random distribution. Figure \ref{Fir_Rate_Dist_Instant_compare} shows the distribution for this special limiting case. The standard deviation for the excitatory was $\mathrm{\sigma_{inst} = 1.41\, Hz}$ and the skewness $\mathrm{v_{inst} = 1.27}$ ($\mathrm{v_{inst,log} = -0.46}$), which makes the asymmetry slightly more pronounced than in Figure \ref{Fir_Rate_Dist_Compare}.  
\begin{figure}
%%% frequ_dist_instant_diff.py
\includegraphics[width=\textwidth]{../../plots/firing_rate_dists/instant_diff_fir_dist_e.png}
\includegraphics[width=\textwidth]{../../plots/firing_rate_dists/instant_diff_fir_dist_i.png}
\caption{Distribution of firing rates for instantaneous diffusion for excitatory (A,B) and inhibitory (A*,B*) population. Data was taken from 2 simulations and $\mathrm{t=1000-1500\,s}$.}
\label{Fir_Rate_Dist_Instant_compare}
\end{figure}

Summing up the results of this section, we can state that stable network activity can be achieved in the LIF-SORN with diffusive homeostasis while producing a broad distribution of firing rates within the excitatory population. We found that this ensemble of activity is maintained on a single cell level, each cell spiking with approximately poissonian statistics at a constant mean rate. The broadness of distribution could be maintained at a relatively constant level over a wide range of diffusion rates. However, we did not find a distribution as right skewed and heavy tailed as reported by Sweeney et al. and numerous experimental studies.

\subsection{Network Topology}
So far, we have only analyzed network activity, whereas in this section we present results that relate to features of synaptic topology. Since the SORN we used for all simulations only included plastic mechanisms affecting recurrent excitatory connections, these were the main subject of our investigations. Moreover, in contrast to the previous section, we did not aim for the emergence of an explicitly \emph{new} feature of synaptic topology, but rather sought to recover properties that had been found in earlier versions of the LIF-SORN.

\subsubsection{Excitatory Connection Fraction}
In the previous version of the SORN, initializing the network with zero recurrent excitatory connections led to a monotonically increasing but saturating excitatory-to-excitatory connection fraction (CF). The growth rate was tuned such that the terminal CF settled at $\mathrm{10\%}$, see \cite[p. 8]{SORN_Paper}. Omitting the distance dependence of connection probability for synaptic growth led to a slightly higher connection fraction. To compare these previous results to the diffusive case, we ran a full simulation under diffusive homeostasis, including the growth phase by setting the target concentration to an appropriate value that was determined in a previous simulation with non-diffusive homeostasis. The resulting time course of CF is depicted in Figure \ref{CF_plot}.
\begin{figure}
%%% plot_CF.py
\includegraphics[width=\textwidth]{../../plots/CF_plot.png}
\caption{Connection fractions of recurrent excitatory synapses. Simulation protocols include all four possible combinations of diffusive/non-diffusive homeostasis and distance-dependent/non-distance-dependent synaptic growth, each variant retained for the entire simulation time.}
\label{CF_plot}
\end{figure}
To our surprise, diffusive homeostasis caused the CF to overshoot its final fraction in the growth phase. Eventually however, it settled at a similar equilibrium of $\mathrm{\approx 10\%}$. To understand this kind of behaviour, we recalled the two mechanisms that directly determine changes within the connection fraction, namely synaptic growth and pruning. The average change of connection fraction is simply proportional to the difference between newly created synapses and those that were removed. Though fluctuating, the synaptic growth rate was kept at a constant level of 920 synapses/second. In consequence, any differences in Figure \ref{CF_plot} must originate in different pruning rates. As explained in section \ref{network simulation}, pruning is performed once per second by collection connections that have fallen under the given weight-threshold. Within this second, a synaptic weight can fall below this value for two reasons: either due to multiplicative normalization or additive STDP. If the weight of a neuron is already very small, multiplicative changes due to normalization have a minor effect compared to weight fluctuations caused by additive STDP, drawing us to the conclusion that differences within the statistics of STDP are the potential cause for the observed overshooting of the CF. Figure \ref{STDP_change} shows the mean and standard deviation of weight changes due to STDP between two normalization steps. Non-diffusive homeostasis has a higher mean as well as a broader distribution of weight fluctuations throughout the beginning of the simulation. However, the difference of mean changes is orders of magnitude smaller than the width of fluctuations. Thus, while it might seem counter-intuitive that a higher positive mean weight change comes with a smaller chance of synaptic survival, we attribute the main cause of overshooting in Figure \ref{CF_plot} to the increased fluctuation of weights, since it raises the chance of going below the pruning threshold within a given time interval.
\begin{figure}
%%% stdp_change_time.py
\includegraphics[width=\textwidth]{../../plots/syn_topology/av_stdp_change_time.png}
\caption{Top: Mean change of synaptic weights (growth and pruning excluded) between two normalization steps. Bottom: Standard deviation for the same data. Both curves correspond to those in Figure \ref{CF_plot} with the same color.}
\label{STDP_change}
\end{figure}
Apart from reproducing the desired connection fraction, previous versions of the LIF-SORN showed an over-representation of bidirectional connections compared to a random graph with equal connectivity \cite{SORN_Paper}. This experimentally observed feature \cite{Markram_Connections_1997,Song_Connectivity_2005} required the presence of a distance dependent connection probability, as described in section \ref{network simulation}. The absence of this breaking of spatial homogeneity even led to an under-representation of bidirectional connections, which is known to be an effect of STDP in recurrent networks \cite{Syn_Plast_Abbott}. As shown in Figure \ref{RC_CFB_plot}, the separation between simulations with and without a spatial connection profile is retained, but a slight shift towards higher fractions of bidirectional connections is preserved over a long time. 
\begin{figure}
%%% plot_RC_CFB.py
\includegraphics[width=\textwidth]{../../plots/syn_topology/RC_CFB_plot.png}
\caption{Fraction of bidirectional connections normalized over the expected fraction for a random graph with equal total connection fraction.}
\label{RC_CFB_plot}
\end{figure}
\subsubsection{Distribution of Synaptic Weights}
A very well-studied property of neural networks is the distribution of synaptic weights. Experimental studies in hippocampus and cortical regions suggest heavy-tailed log-normal-like distribution of synaptic efficacies \cite{Song_Connectivity_2005,Lisman_Synapses_1993,Yasumatsu_Synapses_2008,Loewenstein_Spine_Sizes}. Theoretical models are mainly based on a combination of multiplicative and additive weight dynamics \cite{Loewenstein_Spine_Sizes,Statman_Synapses_2014}, which is in line with our implementation of multiplicative normalization and additive STDP. Figure compares the resulting distributions. We found that we can retain a log-normal-like distribution in combination with diffusive homeostasis. A slightly larger variance can be observed. A possible explanation refers back to our observations in Figure \ref{STDP_change}: regarding STDP as a random process, a broader distribution of weights can be explained by a smaller potentiating effect and a decreased variance of STDP-fluctuations, which is both the case for diffusive homeostasis in the beginning of the simulation. Still, it seems unlikely that a possible effect of these differences is still present at $\mathrm{t=1500\,s}$.
\begin{figure}
%%% plot_weight_dist.py
\includegraphics[width=\textwidth]{../../plots/syn_topology/syn_weight_dist.png}
\caption{Distribution of decadic logarithm of excitatory synaptic weights at $\mathrm{t=1500\,s}$ for diffusive and non-diffusive homeostasis (both with distance-dependent connectivity). Gaussian fits returned $\mathrm{\mu_{diff}=-0.172\, log_{10}(mV)}$, $\mathrm{\mu_{non-diff}=-0.087\, log_{10}(mV)}$, $\mathrm{\sigma_{diff}=0.643\, log_{10}(mV)}$ and $\mathrm{\sigma_{non-diff}=0.418\, log_{10}(mV)}$.}
\label{Weight_Dist}
\end{figure}
\subsubsection{Synaptic Lifetimes}
Synaptic lifetimes have been shown to approximately follow a power law distribution in earlier versions of the LIF-SORN and binary SORN \cite{SORN_Paper,Pengsheng_2013}.


\section{The Firing Rate Distribution in the Network}

As shown in Figure \ref{firing_rate_dist_comp}, the distribution of firing rates within the population of neurons is highly dependent on the diffusion constant $D$, in accordance to the findings by Sweeney et. al. To analyze this dependence, a dynamic mean-field approach was suggested in \cite{Sweeney_Paper}. In short, it consists of set of equations which need to be fulfilled self-consistently.

\begin{align}
\nu &= \langle \phi \rangle = \frac{\sum \phi_i}{N} \label{sweeney_self_consist_rate1} \\
\phi_i &= \phi_i(\mu_i(\nu),\sigma_i(\nu),\theta_i) \label{sweeney_self_consist_rate2} \\
\mu_i &= J_iC_i\nu \tau \label{sweeney_self_consist_rate3} \\
\sigma_i &= J_i\sqrt{C_i\nu  \tau} \label{sweeney_self_consist_rate4}
\end{align}


where $\nu$ is the mean population firing rate, $\phi_i$ the individual firing rate of neuron $i$, $\mu_i$, $\sigma_i$ and $\theta_i$ its synaptic input mean and standard deviation and intrinsic firing threshold respectively and $J_i$, $C_i$ and $\tau$ the neuron's mean synaptic efficacy, number of incoming neurons and the membrane time constant. Self consistency is achieved by iterating through equations \eqref{sweeney_self_consist_rate1} and \eqref{sweeney_self_consist_rate2} until the desired precision is reached.

As a simplification, the authors of \ref{firing_rate_dist_comp} proposed to implement diffusive homeostasis in this context by the following equation:

\begin{equation}
\frac{d\theta_i}{dt} = \frac{1}{\tau_{HIP}} \left(  (1-\alpha)\frac{\phi_i-\phi_0}{\phi_i} +\alpha \frac{\langle \phi \rangle-\phi_0}{\langle \phi \rangle} \right) 
\label{diff_hom_simpl_sweeney}
\end{equation}

$\alpha \: \epsilon \: [0,1]$ thereby acts as a parameter that determines the "mixture" between single-neuron-homeostasis ($\alpha=0$) and the limit of quasi instantaneous spreading of the diffusive signal across the population ($\alpha=1$).

The authors claim that this model reproduces observations in the full network, namely that the steady-state firing rate distribution spreads out due to a larger diffusion constant (or a larger $\alpha$, respectively).

However, in the following, I will argue that the steady-state solution of this simplified model will result in the same firing rate $\phi_0$ for all neurons, no matter what $\alpha$ is set to. This can be seen by setting the left hand side of equ. \eqref{diff_hom_simpl_sweeney} to $0$ (which is necessarily the case in the steady state) and rearranging the equation:

\begin{equation}
(\alpha-1)\frac{\phi_i - \phi_0}{\phi_i} = \alpha \frac{\langle \phi \rangle - \phi_0}{\langle \phi \rangle}
\label{diff_hom_simpl_sweeney_3}
\end{equation}

The right term of the equation is the same for all neurons $i$. Since the left term is monotonic as a function of $\phi_i$, only one specific solution $\phi_i = \Phi$ for all $i$ exists that equals the given term on the right. Furthermore, this implies $\langle \phi \rangle = \Phi$. Thus,

\begin{equation}
(\alpha-1)\frac{\Phi - \phi_0}{\Phi} = \alpha \frac{\Phi - \phi_0}{\Phi}
\label{diff_hom_simpl_sweeney_2}
\end{equation}

which is only fulfilled for $\Phi = \phi_0$.

Moreover, one can argue that this result also implies a fixed distribution of thresholds in the steady state, independent of $\alpha$: Given the result above, one finds
\begin{align}
\phi(\mu_i(\nu),\sigma_i(\nu),\theta_i) &= \phi_0 \label{fixed_thresh_dist_argument1} \\
\mu_i &= J_iC_i \phi_0 \tau \label{fixed_thresh_dist_argument2} \\
\sigma_i &= J_i\sqrt{C_i \phi_0  \tau} \label{fixed_thresh_dist_argument3} \\
\rightarrow \theta_i &= {\phi}^{-1}(J_iC_i \phi_0 \tau,J_i\sqrt{C_i \phi_0  \tau},\phi_0) \label{fixed_thresh_dist_argument4}
\end{align}
which implies that $\theta_i$ only depends on the given network topology.

In \cite{Sweeney_Paper}, a non-interacting population of neurons was simulated while inputs where drawn randomly from a gaussian distribution supposed to model the input statistics of the full network.

To verify our remarks concerning the dynamic mean field model, we simulated a similar population, but used an interacting population of neurons of the same size as in the previous simulations (400 excitatory, 80 inhibitory neurons). This allowed us to directly use a weight matrix acquired by means of a simulation of the full plastic network, taken from the network after $1500s$ (i.E., the "stable" phase).
Individual values for $\mu_i$ and $\sigma_i$ where then calculated according to \eqref{sweeney_self_consist_rate3} and \eqref{sweeney_self_consist_rate4}. Note however that in this case the mean (input) firing rate $\nu$ also takes different values $\nu_i$ for each neuron.

Instead of directly iterating through equations \eqref{sweeney_self_consist_rate1} - \eqref{sweeney_self_consist_rate4} (as done in \cite{Sweeney_Paper}) to fulfil self-consistency, we described the dynamics of the neurons' rates $r_i$ through a continuous dynamic equation

\begin{equation}
\frac{dr_i}{dt} = \frac{1}{\tau_m} \left( -r_i + \phi_i(\mu_i(\nu),\sigma_i(\nu),\theta_i) \right)
\label{dyn_rate_equation}
\end{equation}

where $\tau_m$ is the membrane time constant.

Of course, equation \eqref{sweeney_self_consist_rate1} has to be rewritten accordingly:

\begin{equation}
\nu_i = {\langle r \rangle}_{presyn.,i} \equiv \frac{\sum_{\exists syn. j\rightarrow i} r_j}{N_{presyn., i}}
\label{sweeney_self_consist_rate1_mod}
\end{equation}

Figure \ref{dynamics_rate_threshold_dyn_mean_field_sweeney} depicts the resulting dynamics for $\alpha=0.4$ and $\alpha = 0.8$. Both predictions can be confirmed: All rates approach the same target rate of $3Hz$ and, apparently, thresholds move toward the same state for either choice of $\alpha$. A significant difference only exists within the dynamics leading to the steady state. Roughly, a smaller value of $\alpha$ leads to a faster relaxation. Though, changes in the dynamics appear to be more subtle than a simple rescaling in the time domain.

\begin{figure}
\includegraphics[width=\textwidth]{../../plots/rate_threshold_simpl_hip_alpha/rate_threshold_simpl_hip_alpha_comb}
\caption{Dynamics of rates and thresholds of excitatory population of 400 Neurons (see equations \eqref{dyn_rate_equation} and \eqref{diff_hom_simpl_sweeney}). For both values of $\alpha$, rates and thresholds approach the same steady state.}
\label{dynamics_rate_threshold_dyn_mean_field_sweeney}
\end{figure}

\subsection{Equilibrium in the full diffusive Model}

Since the previous section has proven the simplified model in \cite{Sweeney_Paper} to be incapable of maintaining a broad distribution of firing rates, turning to a more general formulation of the problem seems reasonable, especially if it includes the possibility of the "exact" description of the initial model.

Equation \eqref{NO_dyn} describes the full dynamics of the diffusive neurotransmitter. Furthermore, equation \eqref{simple_NO_dyn} represents a simplification by means of two assumptions, namely the disregard of the diffusive term and the simplification of the process of NO-generation to a simple relation $nNOS_i = C \cdot r_i$, $r_i$ representing a neuron's rate. Here we would like to discuss the implications of an "in-between" simplification, only applying the second one, but retaining the diffusive term:

\begin{equation}
\frac{dNO}{dt}(\mathbf{x},t) =-\lambda NO + D \nabla^2 NO + \sum_{i} \delta^2(\mathbf{x}-\mathbf{x}_{neur,i})\cdot C \cdot r_i
\label{simple_NO_dyn_with_diff}
\end{equation}
As in the previous section, we ask for the steady-state distribution of rates. Thus as a first step, one needs to solve

\begin{equation}
(\lambda - D \nabla^2) NO = \sum_{i} \delta^2(\mathbf{x}-\mathbf{x}_{neur,i})\cdot C \cdot r_i
\label{simple_NO_dyn_with_diff_equil}
\end{equation}
for $\lbrace r_i\rbrace$, such that

\begin{equation}
NO(\mathbf{x}_{neur,i}) = NO_0 \:, \: \forall i
\label{NO_equil_cond}
\end{equation}
Equation \eqref{simple_NO_dyn_with_diff_equil} can be rewritten as

\begin{equation}
\left(\nabla^2 + \left( i\sqrt{\frac{\lambda}{D}}\right)^2\right) NO = \sum_{i} \delta^2(\mathbf{x}-\mathbf{x}_{neur,i})\cdot \frac{- C \cdot r_i}{D}
\label{simple_NO_dyn_with_diff_equil_helmholtz}
\end{equation}
Which is a two-dimensional Helmholtz equation with a superposition of (scaled) Dirac-functions. Thus, the solution of $NO$ is composed of a superposition of shifted and scaled versions of the Green's function of the differential operator on the left of the equation. For each delta function $\delta^2(\mathbf{x}-\mathbf{x}_i)$, the solution is

\begin{equation}
NO_i(\mathbf{x}) = \frac{r_i C}{2 \pi D} K_0 \left(|\mathbf{x}-\mathbf{x}_{neur,i}|\sqrt{\frac{\lambda}{D}} \right)
\label{solution_diff_equil_bessel}
\end{equation}
where $K_0$ is the zeroth modified Bessel function of the second kind. This solution reveals a fundamental problem of modelling the sources of $NO$-production as point sources: that is to say, the fact that $K_0(x)$ diverges to infinity for $x\rightarrow 0$. It is merely due to the finite density of the numeric grid used for the simulation of the diffusion that allows for a finite target value of concentration. Note that this problem only occurs in the two- or three-dimensional version of the differential equation, whereas in one dimension, the fundamental solution can be expressed as an exponential function with respect to the distance to the origin, resulting in a well-defined finite value at $0$.

Generally speaking, no matter how the actual shape of the numeric solution in the equilibrium at a constant production rate will look like, it is expected to be of the form

\begin{align}
NO_i(\mathbf{x}) &= r_i \cdot \psi (d(\mathbf{x}_{neur,i},\mathbf{x})) \label{general_diff_interaction} \\
d(\mathbf{x},\mathbf{y}) &\equiv |\mathbf{x}-\mathbf{y}| \label{eucl_dist}
\end{align}
The full solution is then
\begin{equation}
NO(\mathbf{x}) = \sum_i NO_i(\mathbf{x})
\label{full_sol_diff_equil}
\end{equation}

If we define
\begin{equation}
\psi_{ij} = \psi_{ij} \equiv \psi (d(\mathbf{x}_{neur,i},\mathbf{x}_{neur,i}))
\label{interact_matrix_elements}
\end{equation}
we can express the condition \eqref{NO_equil_cond} as
\begin{equation}
\sum_j \psi_{ij}\cdot r_j = NO_0
\label{NO_equil_cond_interact_matrix}
\end{equation}
or, as an operator
\begin{align}
\hat{\psi}\mathbf{r} &= NO_0 \mathbf{n} \label{NO_equil_cond_interact_matrix_operator} \\
\mathbf{n}&\equiv (1,1,...,1)
\end{align}
The problem of finding the steady-state solution of the homeostatic constraint thus reduces to inverting $\hat{\psi}$:
\begin{equation}
\mathbf{r} = NO_0 \hat{\psi}^{-1} \mathbf{n}
\label{NO_euqil_cond_interact_matrix_operator_solve}
\end{equation}

An example of a distribution of rates acquired from this method is shown in Figure \ref{rate_dist_interact_matrix}.

\begin{figure}
\includegraphics[width=\textwidth]{../../plots/diff_rate_solve.png}
\caption{Distribution of the solution of \eqref{NO_euqil_cond_interact_matrix_operator_solve} with an exponential distance dependent approximation in 2d (similar to the exact solution in 1d). For better statistical significance, calculations where carried out for $1600$ random neurons-positions and $50$ trials in total.}
\label{rate_dist_interact_matrix}
\end{figure}

\subsubsection{Results for an Approximation of the Numerical Steady-State Solution}

If one aims for an appropriate expression for the numerical steady-state solution of a single "point"-source with a constant influx, two things should be of importance: first, it should correctly predict the concentration at the location of the source and second, it should be close to the analytic result in regions further away from the source. One possibility is to use the following "trick" to overcome the divergence of the analytic solution at the origin:

\begin{equation}
NO_{approx.}(d) = \frac{1}{\sqrt{\frac{1}{NO_{source,num.}^2} + \frac{1}{NO(d)^2}}}
\label{Numeric_Solution_Expression_Trick}
\end{equation}

At the pole $NO(0)$, $NO_{approx.}(0)$ then takes the value $NO_{source,num.}$. On the other hand, for larger values of $r$, the term $\frac{1}{NO_{source,num.}^2}$ becomes negligible compared to $ \frac{1}{NO(d)^2}$, thus $NO_{approx.}(d) \rightarrow NO(d)$ for $d \rightarrow \infty$.

To find an approximation for $NO_{source,num.}$, one can interpret this value as a mean of the analytic solution across the square area covered by the corresponding grid cell. As an additional simplification, we substitute the necessary integration over the square grid cell by a circular area of equal size around the source. This calculation yields

\begin{equation}
NO_{source,num.} =  r \cdot \frac{1-h\sqrt{\frac{\lambda}{\pi D}} K_1\left( h\sqrt{\frac{\lambda}{\pi D}}\right) }{h^2 \lambda} \equiv r \cdot \psi_{source,num.}
\label{Numeric_Grid_Bessel_Approx}
\end{equation}
with $r$ being the neuron's rate. Equivalently, one can then define
\begin{equation}
\psi_{approx.}(d) \equiv \frac{1}{\sqrt{\frac{1}{\psi_{source,num.}^2} + \frac{1}{\psi (d)^2}}}
\end{equation}

\subsubsection{Comparison of the Solution of the Random Matrix Equation and the Simulation of the Spiking Network}

\eqref{Numeric_Solution_Expression_Trick} and \eqref{Numeric_Grid_Bessel_Approx} can be used in \eqref{NO_euqil_cond_interact_matrix_operator_solve} for a more accurate description of the distance-dependent diffusive interaction.

In addition, one needs to account for the boundary conditions used in the network simulation. We simulated the network with Neumann boundary conditions (setting the flux through the boundary to zero) as well as periodic boundaries. Both types can be modelled by extending the neurons' population through spatially shifted and mirrored versions of the base population (see Figure \ref{Bound_Cond_Patches}):

\begin{itemize}
\item Periodic boundary conditions are induced by copies of the neurons' positions shifted by $L\cdot (n_x,n_y)$, $n_x,n_y \in \mathbb{Z}$.
\item Zero flux through the boundaries can be achieved by copied positions being shifted by $L\cdot (n_x,n_y)$, $n_x,n_y \in \mathbb{Z}$ \textit{and} mirrored in $x$($y$)-direction if $n_x$($n_y$) is odd.
\end{itemize}

\begin{figure}
\begin{center}
\includegraphics[width=0.5\textwidth]{../../plots/Boundary_Cond_Sketch.png}
\end{center}
\caption{Sketch for patches of copied (and mirrored) positions for periodic (A) and Neumann (B) boundary conditions.}
\label{Bound_Cond_Patches}
\end{figure}

The entries of the operator for periodic boundary conditions $\hat{\psi}_{per.}$ can now calculated by
\begin{equation}
\psi_{ij,per.} = \sum_{n_x,n_y \in \mathbb{Z}} \psi_{approx.} (d(\mathbf{x}_{neur,i},\mathbf{x}_{neur,i} + L \cdot (n_x,n_y)))
\label{Psi_entries_periodic_bound}
\end{equation}
Note that the shift was applied to the second position. Theoretically, $n_x$,$n_y$ is iterated over all integers and in this case it is irrelevant whether to shift the first or the second position. For numerical calculations however, the shift was applied to the second position.

For the Neumann boundary condition, one finds
\begin{align}
\psi_{ij,neum.} &= \sum_{n_x,n_y \in \mathbb{Z}} \psi_{approx.} \left( d(\mathbf{x}_{neur,i},M(\mathbf{x}_{neur,i}) + L \cdot (n_x,n_y)) \right) \label{Psi_entries_neumann_bound} \\
M(\mathbf{x}) &\equiv  
 \begin{pmatrix}
  (-1)^{n_x} & 0\\
  0 & (-1)^{n_y}
 \end{pmatrix}
\mathbf{x} + L \cdot (mod(\left| n_x\right|,2),mod(\left| n_y\right|,2)) \label{Mirror_Operator}
\end{align}

We compared the firing rate distributions acquired from the solution of the random matrix system and those of the full simulated network by means of its standard deviation and skewness.
\begin{figure}
\includegraphics[width=\textwidth]{../../plots/firing_rate_dists/frequ_moments_compare.png}
\caption{Standard deviation and skewness of firing rate distributions for the full spiking network (blue) and the solution of the random matrix model (orange) for Neumann (A,B) and periodic (C,D) boundary conditions.}
\label{frequ_moments_compare}
\end{figure}
While the standard deviation appears to be better fitting the full network in the case of Neumann boundary conditions, the prediction of skewness is more accurate for periodic boundaries. In both versions, the standard deviation seems to be underestimated by the solution of the random matrix equation. This seems reasonable, considering the fact that a network of irregularly spiking neurons "naturally" provides a certain amount of firing rate variability and that during simulation, all plasticity mechanisms where kept in place (changes of presynaptic weights requires an adjustment of the internal threshold to maintain the desired firing rate). 

\subsubsection{Mean-Field Approximation for the Variance of Firing Rates}

Generally, Mean-Field approximations reduce the calculation of a full set of interacting entities (or particles, in the context of physics) to a single instance interacting with an effective mean of the entire field, especially ignoring the influence of the single instance onto the whole set of entities and thus the field itself.

In the system presented here, a single neuron with a firing rate $\nu$ must fulfil the equation

\begin{equation}
\nu =\frac{NO_0 - \sum \limits_{i} \nu_i \psi(d_i)}{\psi_0}
\label{sample_neuron_firing_rate}
\end{equation}
where $i$ indexes over all "remaining" neurons and $d_i$ refers to the euclidean distance of the sample neuron to "field"-neuron $i$. $\psi_0$ is the factor that - multiplied with $\nu$ - yields the $NO$-concentration at the origin of the sample neuron.

Depending on the constraints that one imposes onto the system, one might look for different properties to be extracted from this equation. Specifically, in the simulation protocol that has been used in all previous simulations, the average firing rate was forced to a certain value by means of adjusting the target concentration $NO_0$. A Mean-Field approximation for the average firing rate therefore is of no relevance in this particular case.

However, one might try to give an estimate for the variance of the firing rate distribution in dependence of the diffusion constant $D$. Interpreting $\nu$ in \eqref{sample_neuron_firing_rate} as a stochastic variable, one finds

\begin{equation}
Var[\nu] = \frac{Var[\sum \limits_{i} \nu_i \psi(d_i)]}{\psi_0^2}
\label{variance_sample_neuron_firing_rate}
\end{equation}

As an approximation, one can now replace all $\nu_i$ by the mean activity, which has been forced to a certain value $\nu_0$:

\begin{equation}
Var[\nu] = \frac{\nu_0^2 \cdot Var[\sum \limits_{i} \psi(d_i)]}{\psi_0^2}
\label{variance_sample_neuron_firing_rate_mean_act}
\end{equation}

The random individual neurons' positions are statistically independent, therefore one gets

\begin{equation}
Var[\nu] = \frac{\nu_0^2 \cdot N \cdot Var[\psi(d)]}{\psi_0^2}
\label{variance_sample_neuron_firing_rate_mean_act_indep_positions}
\end{equation}
where $N$ is the number of neurons. One should note however that this expression only applies to the case of open boundaries. Furthermore, depending on the position of the "sample neuron" relative to the population, one can achieve different statistics for $\psi(d)$. The limit case, in which both remarks are of no relevance, is a population of a certain density spreading across a tissue of infinite size.


\bibliography{test_base}
\bibliographystyle{unsrt}
\end{document} 
